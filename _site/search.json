[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Autoencoder for fraud detection",
    "section": "",
    "text": "For this demo, we use a kaggle data set that is readily available (https://www.kaggle.com/mlg-ulb/creditcardfraud). It contains European credit card transactions in the period of September 2013. Note that fraud is a rara phenomenon: of the total of 284,807 transactions only a mere 492 were fraudulent. This corresponds to an incidence rate of 0.172%. This means there is a strong class imbalance.\nThe dataset contains 28 numerical features (V1 - V28) that are the result of a PCA transformation. This is done for confidentiality. On top of these features also the time is registered and the transaction amount. Time is expressed as seconds after the first observation.\nA visual inspection of the data already shows that some of the features have a different distribution for the fraudulent cases compared to the non-fraudulent ones.\nAs preparatory steps, take the (chronologically) first 230,000 data points as a training set and the rest for validation. This resembles the real-life scenario where you will want to predict for future transactions whether they are fraudulent based on the earlier transactions done.\n\nlibrary(readr)\nlibrary(tidyr)\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(ggridges)\nlibrary(purrr)\nlibrary(keras)\nlibrary(caret)\n\n\ndf &lt;- read_csv(\"input/creditcard.csv\", col_types = list(Time = col_number()))\ndf_train &lt;- df %&gt;% filter(row_number(Time) &lt;= 230000) %&gt;% select(-Time)\ndf_test &lt;- df %&gt;% filter(row_number(Time) &gt; 230000) %&gt;% select(-Time)\nprint(head(df_train))\n\n# A tibble: 6 x 30\n      V1      V2    V3     V4      V5      V6      V7      V8     V9     V10\n   &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;\n1 -1.36  -0.0728 2.54   1.38  -0.338   0.462   0.240   0.0987  0.364  0.0908\n2  1.19   0.266  0.166  0.448  0.0600 -0.0824 -0.0788  0.0851 -0.255 -0.167 \n3 -1.36  -1.34   1.77   0.380 -0.503   1.80    0.791   0.248  -1.51   0.208 \n4 -0.966 -0.185  1.79  -0.863 -0.0103  1.25    0.238   0.377  -1.39  -0.0550\n5 -1.16   0.878  1.55   0.403 -0.407   0.0959  0.593  -0.271   0.818  0.753 \n6 -0.426  0.961  1.14  -0.168  0.421  -0.0297  0.476   0.260  -0.569 -0.371 \n# i 20 more variables: V11 &lt;dbl&gt;, V12 &lt;dbl&gt;, V13 &lt;dbl&gt;, V14 &lt;dbl&gt;, V15 &lt;dbl&gt;,\n#   V16 &lt;dbl&gt;, V17 &lt;dbl&gt;, V18 &lt;dbl&gt;, V19 &lt;dbl&gt;, V20 &lt;dbl&gt;, V21 &lt;dbl&gt;,\n#   V22 &lt;dbl&gt;, V23 &lt;dbl&gt;, V24 &lt;dbl&gt;, V25 &lt;dbl&gt;, V26 &lt;dbl&gt;, V27 &lt;dbl&gt;,\n#   V28 &lt;dbl&gt;, Amount &lt;dbl&gt;, Class &lt;dbl&gt;\n\n\n\ndf %&gt;%\n  gather(variable, value, -Class) %&gt;%\n  ggplot(aes(y = as.factor(variable), \n             fill = as.factor(Class), \n             x = percent_rank(value))) +\n  geom_density_ridges()\n\nPicking joint bandwidth of 0.0309"
  },
  {
    "objectID": "index.html#credit-card-data",
    "href": "index.html#credit-card-data",
    "title": "Autoencoder for fraud detection",
    "section": "",
    "text": "For this demo, we use a kaggle data set that is readily available (https://www.kaggle.com/mlg-ulb/creditcardfraud). It contains European credit card transactions in the period of September 2013. Note that fraud is a rara phenomenon: of the total of 284,807 transactions only a mere 492 were fraudulent. This corresponds to an incidence rate of 0.172%. This means there is a strong class imbalance.\nThe dataset contains 28 numerical features (V1 - V28) that are the result of a PCA transformation. This is done for confidentiality. On top of these features also the time is registered and the transaction amount. Time is expressed as seconds after the first observation.\nA visual inspection of the data already shows that some of the features have a different distribution for the fraudulent cases compared to the non-fraudulent ones.\nAs preparatory steps, take the (chronologically) first 230,000 data points as a training set and the rest for validation. This resembles the real-life scenario where you will want to predict for future transactions whether they are fraudulent based on the earlier transactions done.\n\nlibrary(readr)\nlibrary(tidyr)\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(ggridges)\nlibrary(purrr)\nlibrary(keras)\nlibrary(caret)\n\n\ndf &lt;- read_csv(\"input/creditcard.csv\", col_types = list(Time = col_number()))\ndf_train &lt;- df %&gt;% filter(row_number(Time) &lt;= 230000) %&gt;% select(-Time)\ndf_test &lt;- df %&gt;% filter(row_number(Time) &gt; 230000) %&gt;% select(-Time)\nprint(head(df_train))\n\n# A tibble: 6 x 30\n      V1      V2    V3     V4      V5      V6      V7      V8     V9     V10\n   &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;\n1 -1.36  -0.0728 2.54   1.38  -0.338   0.462   0.240   0.0987  0.364  0.0908\n2  1.19   0.266  0.166  0.448  0.0600 -0.0824 -0.0788  0.0851 -0.255 -0.167 \n3 -1.36  -1.34   1.77   0.380 -0.503   1.80    0.791   0.248  -1.51   0.208 \n4 -0.966 -0.185  1.79  -0.863 -0.0103  1.25    0.238   0.377  -1.39  -0.0550\n5 -1.16   0.878  1.55   0.403 -0.407   0.0959  0.593  -0.271   0.818  0.753 \n6 -0.426  0.961  1.14  -0.168  0.421  -0.0297  0.476   0.260  -0.569 -0.371 \n# i 20 more variables: V11 &lt;dbl&gt;, V12 &lt;dbl&gt;, V13 &lt;dbl&gt;, V14 &lt;dbl&gt;, V15 &lt;dbl&gt;,\n#   V16 &lt;dbl&gt;, V17 &lt;dbl&gt;, V18 &lt;dbl&gt;, V19 &lt;dbl&gt;, V20 &lt;dbl&gt;, V21 &lt;dbl&gt;,\n#   V22 &lt;dbl&gt;, V23 &lt;dbl&gt;, V24 &lt;dbl&gt;, V25 &lt;dbl&gt;, V26 &lt;dbl&gt;, V27 &lt;dbl&gt;,\n#   V28 &lt;dbl&gt;, Amount &lt;dbl&gt;, Class &lt;dbl&gt;\n\n\n\ndf %&gt;%\n  gather(variable, value, -Class) %&gt;%\n  ggplot(aes(y = as.factor(variable), \n             fill = as.factor(Class), \n             x = percent_rank(value))) +\n  geom_density_ridges()\n\nPicking joint bandwidth of 0.0309"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  }
]